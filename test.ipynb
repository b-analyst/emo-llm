{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f245b19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_number</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prolific_id</th>\n",
       "      <th>anger</th>\n",
       "      <th>boredom</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>guilt</th>\n",
       "      <th>...</th>\n",
       "      <th>dependable</th>\n",
       "      <th>anxious</th>\n",
       "      <th>open</th>\n",
       "      <th>quiet</th>\n",
       "      <th>sympathetic</th>\n",
       "      <th>disorganized</th>\n",
       "      <th>calm</th>\n",
       "      <th>conventional</th>\n",
       "      <th>did_you_lie?</th>\n",
       "      <th>original_demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>215</td>\n",
       "      <td>2021/07/20 4:12:25 pm EET</td>\n",
       "      <td>f29aa2d9930b2c3005e4176f70479f9e</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>216</td>\n",
       "      <td>2021/07/20 4:24:44 pm EET</td>\n",
       "      <td>18fa800cc02bc318c94d6415c23172cd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>217</td>\n",
       "      <td>2021/07/20 4:25:59 pm EET</td>\n",
       "      <td>99907d478cdbaeb5388db3459408282c</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>218</td>\n",
       "      <td>2021/07/20 4:27:24 pm EET</td>\n",
       "      <td>2475d464084cccf82ac3e72ea8721a5c</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>219</td>\n",
       "      <td>2021/07/20 4:29:02 pm EET</td>\n",
       "      <td>cb83b6f7181863ab7ccd76e203fb2a9e</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>round-6</td>\n",
       "      <td>trust</td>\n",
       "      <td>61102</td>\n",
       "      <td>2021/11/01 10:29:43 pm CET</td>\n",
       "      <td>5271d4d5e8db6f2d589e78070350d4d3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The event really happened in my life.</td>\n",
       "      <td>COPIED FROM: text id 640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6596</th>\n",
       "      <td>round-7</td>\n",
       "      <td>trust</td>\n",
       "      <td>7203</td>\n",
       "      <td>2021/11/09 11:03:40 pm CET</td>\n",
       "      <td>01501eec54f6f0f9286f079c7b23b589</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The event really happened in my life.</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6597</th>\n",
       "      <td>round-7</td>\n",
       "      <td>trust</td>\n",
       "      <td>7204</td>\n",
       "      <td>2021/11/09 11:20:36 pm CET</td>\n",
       "      <td>c12f3d49cc74731bbba3b59659c19cb0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>I never experienced that event, but I really i...</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6598</th>\n",
       "      <td>round-9</td>\n",
       "      <td>trust</td>\n",
       "      <td>922</td>\n",
       "      <td>2021/11/13 10:50:57 pm CET</td>\n",
       "      <td>d3b5e6cede9960b1e75bf85c1feaa844</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The event really happened in my life.</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6599</th>\n",
       "      <td>round-9</td>\n",
       "      <td>trust</td>\n",
       "      <td>923</td>\n",
       "      <td>2021/11/13 10:56:49 pm CET</td>\n",
       "      <td>41e9d0a7b7e43fc3b15e1b67287279da</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The event really happened in my life.</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6600 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     round_number emotion  text_id                   timestamp  \\\n",
       "0         round-2   anger      215   2021/07/20 4:12:25 pm EET   \n",
       "1         round-2   anger      216   2021/07/20 4:24:44 pm EET   \n",
       "2         round-2   anger      217   2021/07/20 4:25:59 pm EET   \n",
       "3         round-2   anger      218   2021/07/20 4:27:24 pm EET   \n",
       "4         round-2   anger      219   2021/07/20 4:29:02 pm EET   \n",
       "...           ...     ...      ...                         ...   \n",
       "6595      round-6   trust    61102  2021/11/01 10:29:43 pm CET   \n",
       "6596      round-7   trust     7203  2021/11/09 11:03:40 pm CET   \n",
       "6597      round-7   trust     7204  2021/11/09 11:20:36 pm CET   \n",
       "6598      round-9   trust      922  2021/11/13 10:50:57 pm CET   \n",
       "6599      round-9   trust      923  2021/11/13 10:56:49 pm CET   \n",
       "\n",
       "                           prolific_id  anger  boredom  disgust  fear  guilt  \\\n",
       "0     f29aa2d9930b2c3005e4176f70479f9e      1        3        1     1      1   \n",
       "1     18fa800cc02bc318c94d6415c23172cd      4        1        1     2      1   \n",
       "2     99907d478cdbaeb5388db3459408282c      1        3        2     2      2   \n",
       "3     2475d464084cccf82ac3e72ea8721a5c      1        5        2     1      1   \n",
       "4     cb83b6f7181863ab7ccd76e203fb2a9e      1        3        1     1      1   \n",
       "...                                ...    ...      ...      ...   ...    ...   \n",
       "6595  5271d4d5e8db6f2d589e78070350d4d3      1        1        1     1      1   \n",
       "6596  01501eec54f6f0f9286f079c7b23b589      4        3        4     4      3   \n",
       "6597  c12f3d49cc74731bbba3b59659c19cb0      1        3        1     1      1   \n",
       "6598  d3b5e6cede9960b1e75bf85c1feaa844      1        3        1     1      1   \n",
       "6599  41e9d0a7b7e43fc3b15e1b67287279da      1        2        1     1      1   \n",
       "\n",
       "      ...  dependable  anxious  open  quiet  sympathetic  disorganized  calm  \\\n",
       "0     ...         7.0      5.0   7.0    7.0          7.0           2.0   3.0   \n",
       "1     ...         6.0      5.0   5.0    4.0          5.0           3.0   4.0   \n",
       "2     ...         5.0      6.0   3.0    7.0          7.0           4.0   6.0   \n",
       "3     ...         5.0      5.0   5.0    5.0          5.0           4.0   5.0   \n",
       "4     ...         5.0      5.0   6.0    3.0          6.0           5.0   5.0   \n",
       "...   ...         ...      ...   ...    ...          ...           ...   ...   \n",
       "6595  ...         3.0      5.0   6.0    2.0          6.0           6.0   5.0   \n",
       "6596  ...         5.0      5.0   4.0    4.0          5.0           2.0   5.0   \n",
       "6597  ...         3.0      5.0   5.0    7.0          4.0           5.0   3.0   \n",
       "6598  ...         5.0      4.0   6.0    7.0          7.0           2.0   7.0   \n",
       "6599  ...         3.0      2.0   5.0    5.0          6.0           5.0   6.0   \n",
       "\n",
       "     conventional                                       did_you_lie?  \\\n",
       "0             2.0                                                 --   \n",
       "1             4.0                                                 --   \n",
       "2             5.0                                                 --   \n",
       "3             3.0                                                 --   \n",
       "4             3.0                                                 --   \n",
       "...           ...                                                ...   \n",
       "6595          2.0              The event really happened in my life.   \n",
       "6596          5.0              The event really happened in my life.   \n",
       "6597          6.0  I never experienced that event, but I really i...   \n",
       "6598          2.0              The event really happened in my life.   \n",
       "6599          4.0              The event really happened in my life.   \n",
       "\n",
       "         original_demographics  \n",
       "0                     ORIGINAL  \n",
       "1                     ORIGINAL  \n",
       "2                     ORIGINAL  \n",
       "3                     ORIGINAL  \n",
       "4                     ORIGINAL  \n",
       "...                        ...  \n",
       "6595  COPIED FROM: text id 640  \n",
       "6596                  ORIGINAL  \n",
       "6597                  ORIGINAL  \n",
       "6598                  ORIGINAL  \n",
       "6599                  ORIGINAL  \n",
       "\n",
       "[6600 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/enVent_gen_Data.csv', encoding='ISO-8859-1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ac8a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['round_number', 'emotion', 'text_id', 'timestamp', 'prolific_id',\n",
       "       'anger', 'boredom', 'disgust', 'fear', 'guilt', 'joy', 'pride',\n",
       "       'relief', 'sadness', 'shame', 'surprise', 'trust', 'generated_text',\n",
       "       'hidden_emo_text', 'event_duration', 'emotion_duration', 'intensity',\n",
       "       'confidence', 'suddenness', 'familiarity', 'predict_event',\n",
       "       'pleasantness', 'unpleasantness', 'goal_relevance', 'chance_responsblt',\n",
       "       'self_responsblt', 'other_responsblt', 'predict_conseq', 'goal_support',\n",
       "       'urgency', 'self_control', 'other_control', 'chance_control',\n",
       "       'accept_conseq', 'standards', 'social_norms', 'attention',\n",
       "       'not_consider', 'effort', 'previous_participation', 'age', 'gender',\n",
       "       'education', 'ethnicity', 'extravert', 'critical', 'dependable',\n",
       "       'anxious', 'open', 'quiet', 'sympathetic', 'disorganized', 'calm',\n",
       "       'conventional', 'did_you_lie?', 'original_demographics'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bbeb6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       people get under my skin. Like for example if ...\n",
       "1       I was driving on the highway and someone cut m...\n",
       "2       someone misunderstands me and takes it out of ...\n",
       "3       a child called me a name behind my back after ...\n",
       "4       I was driving home from work and an individual...\n",
       "                              ...                        \n",
       "6595    I left my daughter with her nursery for the fi...\n",
       "6596    I felt ... when I met my partner because he ma...\n",
       "6597      I asked someone to help me at work and they did\n",
       "6598    I got married to my husband. When we said our ...\n",
       "6599    my girlfriend travelled all the way up the cou...\n",
       "Name: hidden_emo_text, Length: 6600, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"hidden_emo_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a53253f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       anger\n",
       "1       anger\n",
       "2       anger\n",
       "3       anger\n",
       "4       anger\n",
       "        ...  \n",
       "6595    trust\n",
       "6596    trust\n",
       "6597    trust\n",
       "6598    trust\n",
       "6599    trust\n",
       "Name: emotion, Length: 6600, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bbb99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kchun\\desktop\\emo-llm\\experiments\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab95ec56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe019b8aa6634b6e99763a0ed7a55202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8e0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import json\n",
    "\n",
    "with open(r\"C:\\Users\\kchun\\Desktop\\EmotionBench\\situations.json\", 'rb') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "emotions = []\n",
    "situations = []\n",
    "inputs = []\n",
    "for item in data[\"emotions\"]:\n",
    "    emotions.append(item[\"name\"])\n",
    "    for sit in item[\"factors\"]:\n",
    "        for sen in sit[\"scenarios\"]:\n",
    "            situations.append(\n",
    "                {\n",
    "                    \"label\": item[\"name\"],\n",
    "                    \"scenarios\": sen\n",
    "                }\n",
    "            )\n",
    "\n",
    "dataset = pd.DataFrame(situations)\n",
    "dataset.to_csv(\"emotionbench_scenarios_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e993433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anger',\n",
       " 'Anxiety',\n",
       " 'Depression',\n",
       " 'Frustration',\n",
       " 'Jealousy',\n",
       " 'Guilt',\n",
       " 'Fear',\n",
       " 'Embarrassment']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae452d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>scenarios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you discuss your opinions with your paren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If your classmate talks back to you when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If some older people like your parents are dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When your classmate says the Earth is flat and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you know you're right, but the others say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are shopping at a local grocery store. Bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are attending a formal party at your boss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are leaving class with an acquaintance you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are assigned to give a presentation for cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are at a public beach and you feel like go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                          scenarios\n",
       "0            Anger  When you discuss your opinions with your paren...\n",
       "1            Anger  If your classmate talks back to you when there...\n",
       "2            Anger  If some older people like your parents are dis...\n",
       "3            Anger  When your classmate says the Earth is flat and...\n",
       "4            Anger  When you know you're right, but the others say...\n",
       "..             ...                                                ...\n",
       "423  Embarrassment  You are shopping at a local grocery store. Bec...\n",
       "424  Embarrassment  You are attending a formal party at your boss'...\n",
       "425  Embarrassment  You are leaving class with an acquaintance you...\n",
       "426  Embarrassment  You are assigned to give a presentation for cl...\n",
       "427  Embarrassment  You are at a public beach and you feel like go...\n",
       "\n",
       "[428 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca95c177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9aeb6af50d4428d95c9feeaa28d7058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f8b4a4dc034b6487a98df5a8bd4908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[32m     85\u001b[39m extraction_tokens = \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     86\u001b[39m extraction_layers = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(model.config.num_hidden_layers))\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m all_hidden_states = \u001b[43mextract_hidden_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_locs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextraction_locs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextraction_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_tokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m torch.save(all_hidden_states, \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33moutputs/Phi-3.5-mini-instruct/hidden_states_layers_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextraction_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_locs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextraction_locs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_tokens_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextraction_tokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pt\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\utils.py:448\u001b[39m, in \u001b[36mextract_hidden_states\u001b[39m\u001b[34m(dataloader, tokenizer, model, logger, extraction_layers, extraction_locs, extraction_tokens, do_final_cat, return_tokenized_input)\u001b[39m\n\u001b[32m    439\u001b[39m inputs = tokenizer(\n\u001b[32m    440\u001b[39m     batch_texts,\n\u001b[32m    441\u001b[39m     padding=\u001b[33m'\u001b[39m\u001b[33mmax_length\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m max_length \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mlongest\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    444\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    445\u001b[39m ).to(model.device)\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    450\u001b[39m cache_dict_ = outputs[\u001b[32m1\u001b[39m]\n\u001b[32m    452\u001b[39m \u001b[38;5;66;03m# Determine extraction tokens - now all sequences are padded to same length\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\transformer_lens\\hook_points.py:560\u001b[39m, in \u001b[36mHookedRootModule.run_with_cache\u001b[39m\u001b[34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[39m\n\u001b[32m    546\u001b[39m cache_dict, fwd, bwd = \u001b[38;5;28mself\u001b[39m.get_caching_hooks(\n\u001b[32m    547\u001b[39m     names_filter,\n\u001b[32m    548\u001b[39m     incl_bwd,\n\u001b[32m   (...)\u001b[39m\u001b[32m    551\u001b[39m     pos_slice=pos_slice,\n\u001b[32m    552\u001b[39m )\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.hooks(\n\u001b[32m    555\u001b[39m     fwd_hooks=fwd,\n\u001b[32m    556\u001b[39m     bwd_hooks=bwd,\n\u001b[32m    557\u001b[39m     reset_hooks_end=reset_hooks_end,\n\u001b[32m    558\u001b[39m     clear_contexts=clear_contexts,\n\u001b[32m    559\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m     model_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[32m    562\u001b[39m         model_out.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\LLMs\\my_phi3.py:1293\u001b[39m, in \u001b[36mPhi3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[39m\n\u001b[32m   1290\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1292\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1306\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\LLMs\\my_phi3.py:1004\u001b[39m, in \u001b[36mPhi3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    993\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    994\u001b[39m         decoder_layer.\u001b[34m__call__\u001b[39m,\n\u001b[32m    995\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1001\u001b[39m         cache_position,\n\u001b[32m   1002\u001b[39m     )\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\LLMs\\my_phi3.py:726\u001b[39m, in \u001b[36mPhi3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    723\u001b[39m \u001b[38;5;28mself\u001b[39m.hook_after_attn_normalization(hidden_states) \u001b[38;5;66;03m#added\u001b[39;00m\n\u001b[32m    725\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m.hook_after_attn(hidden_states) \u001b[38;5;66;03m#added\u001b[39;00m\n\u001b[32m    737\u001b[39m hidden_states = residual + \u001b[38;5;28mself\u001b[39m.resid_attn_dropout(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\LLMs\\my_phi3.py:608\u001b[39m, in \u001b[36mPhi3SdpaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    607\u001b[39m     kv_seq_len += past_key_value.get_seq_length(kv_seq_len, \u001b[38;5;28mself\u001b[39m.layer_idx)\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m cos, sin = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrotary_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkv_seq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\LLMs\\my_phi3.py:220\u001b[39m, in \u001b[36mPhi3LongRoPEScaledRotaryEmbedding.forward\u001b[39m\u001b[34m(self, x, position_ids, seq_len)\u001b[39m\n\u001b[32m    218\u001b[39m device_type = x.device.type\n\u001b[32m    219\u001b[39m device_type = device_type \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device_type, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m device_type != \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minv_freq_expanded\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids_expanded\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43memb\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kchun\\Desktop\\emo-llm\\experiments\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:391\u001b[39m, in \u001b[36mautocast.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    383\u001b[39m                 args = (\n\u001b[32m    384\u001b[39m                     \u001b[38;5;28mself\u001b[39m.device,\n\u001b[32m    385\u001b[39m                     \u001b[38;5;28mself\u001b[39m.fast_dtype,\n\u001b[32m    386\u001b[39m                     \u001b[38;5;28mself\u001b[39m._enabled,\n\u001b[32m    387\u001b[39m                     \u001b[38;5;28mself\u001b[39m._cache_enabled,\n\u001b[32m    388\u001b[39m                 )\n\u001b[32m    389\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m mode.__torch_function__(torch.amp._enter_autocast, (), args)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_val: Any, exc_tb: Any):  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._jit_internal.is_scripting():\n\u001b[32m    393\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def get_probes(classifier_file_path, classes, layer, loc):\n",
    "    def load_classifier_weights(classifier_file_path, layer, loc):\n",
    "        \"\"\"\n",
    "        Loads classifier weights and biases from a .pt file.\n",
    "\n",
    "        Args:\n",
    "            filepath (str): The path to the .pt file.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A tuple containing the weights (torch.Tensor) and bias (torch.Tensor).\n",
    "                  Returns (None, None) if the file does not contain 'weights' and 'bias'.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            saved_data = torch.load(classifier_file_path, weights_only=False, map_location='cpu')\n",
    "            if isinstance(saved_data, dict) and 'weights' in saved_data and 'bias' in saved_data:\n",
    "                return saved_data[layer][loc][-1]['weights'], saved_data[layer][loc][-1]['bias']\n",
    "            else:\n",
    "                print(f\"Warning: The file at {classifier_file_path} does not contain 'weights' and 'bias'.\")\n",
    "                return None, None\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: File not found at {classifier_file_path}\")\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while loading the file: {e}\")\n",
    "            return None, None\n",
    "    weights, bias = load_classifier_weights(classifier_file_path, layer, loc)\n",
    "    return weights, bias\n",
    "\n",
    "\n",
    "\n",
    "def my_probe_classification(classifier, all_hidden_states):\n",
    "    X = all_hidden_states.reshape(all_hidden_states.shape[0], -1)\n",
    "    return classifier.predict(X)\n",
    "\n",
    "\n",
    "from utils import emotion_to_token_ids, TextDataset, extract_hidden_states, Log\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from LLMs.my_gemma2 import Gemma2ForCausalLM\n",
    "from LLMs.my_olmo import OlmoForCausalLM\n",
    "from LLMs.my_llama import LlamaForCausalLM\n",
    "from LLMs.my_phi3 import Phi3ForCausalLM\n",
    "\n",
    "log = Log(log_name='intervention')\n",
    "logger = log.logger\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('google/gemma-2-2b-it')\n",
    "# model = Gemma2ForCausalLM.from_pretrained('google/gemma-2-2b-it', device_map='auto')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('allenai/OLMo-1B-hf')\n",
    "# model = OlmoForCausalLM.from_pretrained('allenai/OLMo-1B-hf', device_map='auto')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-1B-Instruct')\n",
    "# model = LlamaForCausalLM.from_pretrained('meta-llama/Llama-3.2-1B-Instruct', device_map='auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/Phi-3.5-mini-instruct')\n",
    "model = Phi3ForCausalLM.from_pretrained('microsoft/Phi-3.5-mini-instruct', device_map=\"auto\")\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "extraction_layers = list(range(model.config.num_hidden_layers))\n",
    "extraction_locs = [3, 6, 7]\n",
    "data = pd.read_csv(\"emotionbench_scenarios_processed.csv\")\n",
    "emotions_to_tokenized_ids = emotion_to_token_ids(emotions, tokenizer)\n",
    "emotion_to_id = {emotion: i for i, emotion in enumerate(emotions)}\n",
    "id_to_emotion = {v: k for k, v in emotion_to_id.items()}\n",
    "\n",
    "def generate(dataset):\n",
    "    emotion_to_id = {emotion: i for i, emotion in enumerate(emotions)}\n",
    "    id_to_emotion = {v: k for k, v in emotion_to_id.items()}\n",
    "    dataset[\"emotion_id\"] = dataset[\"label\"].map(emotion_to_id)\n",
    "    labels = torch.from_numpy(dataset['emotion_id'].to_numpy())\n",
    "    data = TextDataset(dataset[\"scenarios\"].tolist(), labels)\n",
    "    dataloader = DataLoader(data, batch_size=1, shuffle=False)\n",
    "    return dataloader, labels\n",
    "\n",
    "\n",
    "dataloader, labels = generate(data)\n",
    "extraction_locs = [3, 6, 7]\n",
    "# extraction_locs = [7]\n",
    "\n",
    "extraction_tokens = 'auto'\n",
    "extraction_layers = list(range(model.config.num_hidden_layers))\n",
    "\n",
    "all_hidden_states = extract_hidden_states(dataloader, tokenizer, model, logger, extraction_locs=extraction_locs, extraction_layers=extraction_layers, extraction_tokens = extraction_tokens)\n",
    "torch.save(all_hidden_states, f'outputs/Phi-3.5-mini-instruct/hidden_states_layers_{extraction_layers}_locs_{extraction_locs}_tokens_{extraction_tokens}.pt')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05b7362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32,\n",
       " 24,\n",
       " 61,\n",
       " 45,\n",
       " 27,\n",
       " 25,\n",
       " 59,\n",
       " 57,\n",
       " 14,\n",
       " 21,\n",
       " 22,\n",
       " 62,\n",
       " 40,\n",
       " 36,\n",
       " 16,\n",
       " 32,\n",
       " 34,\n",
       " 53,\n",
       " 44,\n",
       " 39,\n",
       " 43,\n",
       " 36,\n",
       " 27,\n",
       " 40,\n",
       " 36,\n",
       " 19,\n",
       " 48,\n",
       " 24,\n",
       " 28,\n",
       " 31,\n",
       " 24,\n",
       " 34,\n",
       " 59,\n",
       " 37,\n",
       " 37,\n",
       " 13,\n",
       " 36,\n",
       " 29,\n",
       " 28,\n",
       " 32,\n",
       " 84,\n",
       " 36,\n",
       " 25,\n",
       " 44,\n",
       " 34,\n",
       " 50,\n",
       " 23,\n",
       " 19,\n",
       " 15,\n",
       " 40,\n",
       " 38,\n",
       " 35,\n",
       " 17,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 17,\n",
       " 15,\n",
       " 9,\n",
       " 12,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 13,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 12,\n",
       " 16,\n",
       " 14,\n",
       " 17,\n",
       " 11,\n",
       " 13,\n",
       " 7,\n",
       " 12,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 22,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 13,\n",
       " 10,\n",
       " 14,\n",
       " 21,\n",
       " 13,\n",
       " 8,\n",
       " 128,\n",
       " 13,\n",
       " 13,\n",
       " 11,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 17,\n",
       " 13,\n",
       " 9,\n",
       " 93,\n",
       " 59,\n",
       " 69,\n",
       " 74,\n",
       " 84,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 14,\n",
       " 13,\n",
       " 16,\n",
       " 13,\n",
       " 63,\n",
       " 82,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 12,\n",
       " 79,\n",
       " 70,\n",
       " 72,\n",
       " 64,\n",
       " 69,\n",
       " 51,\n",
       " 71,\n",
       " 71,\n",
       " 69,\n",
       " 76,\n",
       " 76,\n",
       " 67,\n",
       " 85,\n",
       " 71,\n",
       " 90,\n",
       " 81,\n",
       " 67,\n",
       " 83,\n",
       " 78,\n",
       " 67,\n",
       " 75,\n",
       " 78,\n",
       " 73,\n",
       " 84,\n",
       " 58,\n",
       " 74,\n",
       " 66,\n",
       " 72,\n",
       " 75,\n",
       " 83,\n",
       " 77,\n",
       " 81,\n",
       " 60,\n",
       " 66,\n",
       " 84,\n",
       " 40,\n",
       " 34,\n",
       " 21,\n",
       " 13,\n",
       " 30,\n",
       " 11,\n",
       " 11,\n",
       " 15,\n",
       " 14,\n",
       " 21,\n",
       " 22,\n",
       " 28,\n",
       " 15,\n",
       " 16,\n",
       " 9,\n",
       " 38,\n",
       " 31,\n",
       " 27,\n",
       " 23,\n",
       " 16,\n",
       " 18,\n",
       " 37,\n",
       " 12,\n",
       " 9,\n",
       " 26,\n",
       " 20,\n",
       " 21,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 21,\n",
       " 22,\n",
       " 20,\n",
       " 21,\n",
       " 17,\n",
       " 21,\n",
       " 18,\n",
       " 20,\n",
       " 20,\n",
       " 18,\n",
       " 18,\n",
       " 21,\n",
       " 22,\n",
       " 95,\n",
       " 95,\n",
       " 128,\n",
       " 42,\n",
       " 37,\n",
       " 66,\n",
       " 102,\n",
       " 52,\n",
       " 8,\n",
       " 7,\n",
       " 10,\n",
       " 8,\n",
       " 13,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 13,\n",
       " 102,\n",
       " 53,\n",
       " 89,\n",
       " 113,\n",
       " 64,\n",
       " 80,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 14,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 19,\n",
       " 10,\n",
       " 11,\n",
       " 17,\n",
       " 13,\n",
       " 12,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 5,\n",
       " 14,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 39,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 79,\n",
       " 97,\n",
       " 53,\n",
       " 105,\n",
       " 64,\n",
       " 126,\n",
       " 91,\n",
       " 128,\n",
       " 128,\n",
       " 113,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 19,\n",
       " 12,\n",
       " 10,\n",
       " 11,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 7,\n",
       " 9,\n",
       " 13,\n",
       " 7,\n",
       " 5,\n",
       " 19,\n",
       " 4,\n",
       " 6,\n",
       " 15,\n",
       " 39,\n",
       " 37,\n",
       " 32,\n",
       " 40,\n",
       " 24,\n",
       " 33,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 24,\n",
       " 27,\n",
       " 30,\n",
       " 25,\n",
       " 27,\n",
       " 26,\n",
       " 24,\n",
       " 35,\n",
       " 36,\n",
       " 45,\n",
       " 37,\n",
       " 24,\n",
       " 28,\n",
       " 25,\n",
       " 32,\n",
       " 42,\n",
       " 23,\n",
       " 27,\n",
       " 33,\n",
       " 33,\n",
       " 30,\n",
       " 41,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 30,\n",
       " 38,\n",
       " 25,\n",
       " 32,\n",
       " 35,\n",
       " 44,\n",
       " 37,\n",
       " 51,\n",
       " 40,\n",
       " 29,\n",
       " 30,\n",
       " 48,\n",
       " 45,\n",
       " 44,\n",
       " 26,\n",
       " 26,\n",
       " 35,\n",
       " 35,\n",
       " 28,\n",
       " 32,\n",
       " 27,\n",
       " 26,\n",
       " 28,\n",
       " 33,\n",
       " 34,\n",
       " 128,\n",
       " 128,\n",
       " 77,\n",
       " 79,\n",
       " 82,\n",
       " 111,\n",
       " 128,\n",
       " 128,\n",
       " 80,\n",
       " 89,\n",
       " 103,\n",
       " 66,\n",
       " 71,\n",
       " 58,\n",
       " 40,\n",
       " 74,\n",
       " 61,\n",
       " 101,\n",
       " 44,\n",
       " 109,\n",
       " 92,\n",
       " 69,\n",
       " 52,\n",
       " 92,\n",
       " 82,\n",
       " 86,\n",
       " 100,\n",
       " 128,\n",
       " 37,\n",
       " 43,\n",
       " 54,\n",
       " 30,\n",
       " 51,\n",
       " 35,\n",
       " 61,\n",
       " 61,\n",
       " 68,\n",
       " 56,\n",
       " 64,\n",
       " 25,\n",
       " 62,\n",
       " 64,\n",
       " 60,\n",
       " 85,\n",
       " 27,\n",
       " 42,\n",
       " 78,\n",
       " 84,\n",
       " 82,\n",
       " 89,\n",
       " 88,\n",
       " 51]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_lens = [\n",
    "    len(tokenizer(\n",
    "            t, \n",
    "            return_tensors=\"pt\", \n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            truncation=True,\n",
    "        )[\"input_ids\"][0]\n",
    "    ) for t in dataset['scenarios']\n",
    "]\n",
    "\n",
    "prompt_lens  # list of N ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a25b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = torch.tensor([n-1 for n in prompt_lens]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb584bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_hidden_states' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# all_hidden_states = torch.load(r'C:\\Users\\kchun\\Desktop\\emo-llm\\outputs\\OLMo-1B-hf\\hidden_states_layers_[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]_locs_[3, 6, 7]_tokens_auto.pt')\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Get actual token indices from the tensor shape\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extraction_tokens == \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     actual_extraction_tokens = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[43mall_hidden_states\u001b[49m.shape[\u001b[32m3\u001b[39m]))  \u001b[38;5;66;03m# token dimension\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      7\u001b[39m     actual_extraction_tokens = extraction_tokens\n",
      "\u001b[31mNameError\u001b[39m: name 'all_hidden_states' is not defined"
     ]
    }
   ],
   "source": [
    "from utils import apply_classification_probe\n",
    "# all_hidden_states = torch.load(r'C:\\Users\\kchun\\Desktop\\emo-llm\\outputs\\OLMo-1B-hf\\hidden_states_layers_[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]_locs_[3, 6, 7]_tokens_auto.pt')\n",
    "# Get actual token indices from the tensor shape\n",
    "if extraction_tokens == 'auto':\n",
    "    actual_extraction_tokens = list(range(all_hidden_states.shape[3]))  # token dimension\n",
    "else:\n",
    "    actual_extraction_tokens = extraction_tokens\n",
    "\n",
    "print(f\"Extracted shape: {all_hidden_states.shape}\")\n",
    "print(f\"Token positions: {len(actual_extraction_tokens)} tokens (0 to {len(actual_extraction_tokens)-1})\")\n",
    "\n",
    "res = torch.load(r'C:\\Users\\kchun\\Desktop\\emo-llm\\outputs\\Phi-3.5-mini-instruct\\emotion_probing_layers_[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]_locs_[3, 6, 7]_tokens_[-1].pt', weights_only=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0c8e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02825185, -0.16013838,  0.15699579, ...,  0.0301619 ,\n",
       "         0.14712108, -0.08962646],\n",
       "       [-0.01585532,  0.24433851,  0.16688438, ...,  0.05721496,\n",
       "         0.08291397,  0.21405251],\n",
       "       [-0.08447002, -0.19527781, -0.00778105, ...,  0.06014358,\n",
       "        -0.0342375 ,  0.11932172],\n",
       "       ...,\n",
       "       [ 0.08123267, -0.05367934,  0.15290011, ..., -0.02938215,\n",
       "         0.08915906, -0.13925691],\n",
       "       [-0.03856578,  0.10689569, -0.10680969, ...,  0.26889982,\n",
       "        -0.37628452, -0.23828829],\n",
       "       [ 0.08373506, -0.09112453, -0.04720875, ..., -0.11647892,\n",
       "         0.09834736, -0.06286018]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][3][-1][\"weights\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3695009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "        [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "        [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "        ...,\n",
       "        [ 0.0282,  0.0139,  0.1755,  ..., -0.0575, -0.0669,  0.0675],\n",
       "        [ 0.0663,  0.0464,  0.0461,  ..., -0.0200, -0.1039,  0.0578],\n",
       "        [ 0.0114, -0.2040,  0.4048,  ...,  0.3357,  0.0723, -0.0108]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[0,0,-1,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "4ee5f6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c5e582f3484a3390a00f5252e56f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/428 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = {}\n",
    "for i, example in tqdm(enumerate(dataset['scenarios']), total=len(dataset['scenarios'])):\n",
    "    logits_tok = []\n",
    "    entry = {}\n",
    "    # print(example)\n",
    "    entry[\"prompt\"] = example\n",
    "    entry[\"layers\"] = []\n",
    "    for j, layer in enumerate(extraction_layers):\n",
    "        # print(layer)\n",
    "        row = {\n",
    "            f\"layer_{layer}\": {}\n",
    "        }\n",
    "        hs_slice = all_hidden_states[i, j, 2, :]\n",
    "        start_token_idx = 0\n",
    "        end_token_idx = prompt_lens[i] - 1\n",
    "        # hs_slice = hs_slice[start_token_idx:end_token_idx]\n",
    "        # hs_slice = hs_slice[-1]\n",
    "        # print(hs_slice.shape)\n",
    "        w_np = res[layer][7][-1]['weights']  # numpy float64 [C, D]\n",
    "        # print(w_np.shape)\n",
    "        b_np = res[layer][7][-1]['bias']  \n",
    "        w = torch.from_numpy(w_np).to(hs_slice.device).to(hs_slice.dtype)  # [C, D]\n",
    "        b = torch.from_numpy(b_np).to(hs_slice.device).to(hs_slice.dtype)     # [C]\n",
    "        logits = apply_classification_probe(hs_slice, w, b)      # [N, C]\n",
    "        # print(logits.shape)\n",
    "        probs = torch.softmax(logits, dim=-1)                    # probability breakdown\n",
    "        # print(probs.shape)\n",
    "        row[f\"layer_{layer}\"][\"probs\"] = probs\n",
    "        row[f\"layer_{layer}\"][\"preds\"] = probs.argmax(dim=-1)\n",
    "        entry[\"layers\"].append(row)\n",
    "    results[i] = entry\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7fed57f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3959e-03, 7.3087e-01, 1.1320e-01,  ..., 3.5162e-03, 1.3223e-04,\n",
       "         8.3230e-05],\n",
       "        [2.3959e-03, 7.3087e-01, 1.1320e-01,  ..., 3.5162e-03, 1.3223e-04,\n",
       "         8.3230e-05],\n",
       "        [2.3959e-03, 7.3087e-01, 1.1320e-01,  ..., 3.5162e-03, 1.3223e-04,\n",
       "         8.3230e-05],\n",
       "        ...,\n",
       "        [2.4881e-03, 4.5043e-02, 4.4116e-02,  ..., 1.6736e-04, 4.2839e-01,\n",
       "         1.7871e-03],\n",
       "        [2.5651e-04, 7.8749e-01, 2.0264e-02,  ..., 4.1791e-03, 2.7206e-03,\n",
       "         1.8265e-03],\n",
       "        [1.2055e-01, 6.4540e-03, 3.6029e-01,  ..., 4.1653e-04, 4.3638e-01,\n",
       "         8.8403e-04]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[40][\"layers\"][0][f\"layer_{0}\"][\"probs\"]\n",
    "# print(emotions_list)\n",
    "\n",
    "# print(dataset['scenarios'][39])\n",
    "# print(dataset['scenarios'][40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2ebd9a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>scenarios</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you discuss your opinions with your paren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If your classmate talks back to you when there...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If some older people like your parents are dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When your classmate says the Earth is flat and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you know you're right, but the others say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are shopping at a local grocery store. Bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are attending a formal party at your boss'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are leaving class with an acquaintance you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are assigned to give a presentation for cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are at a public beach and you feel like go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                          scenarios\n",
       "0            Anger  When you discuss your opinions with your paren...\n",
       "1            Anger  If your classmate talks back to you when there...\n",
       "2            Anger  If some older people like your parents are dis...\n",
       "3            Anger  When your classmate says the Earth is flat and...\n",
       "4            Anger  When you know you're right, but the others say...\n",
       "..             ...                                                ...\n",
       "423  Embarrassment  You are shopping at a local grocery store. Bec...\n",
       "424  Embarrassment  You are attending a formal party at your boss'...\n",
       "425  Embarrassment  You are leaving class with an acquaintance you...\n",
       "426  Embarrassment  You are assigned to give a presentation for cl...\n",
       "427  Embarrassment  You are at a public beach and you feel like go...\n",
       "\n",
       "[428 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e4171b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for n, example in results.items():\n",
    "    print(n)\n",
    "    print(len(example[\"layers\"][0][\"layer_0\"][\"probs\"][-1]))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0b9b027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e36845ebc5449c8a34ab725b68ecbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_list = ['anger', 'boredom', 'disgust', 'fear', 'guilt', 'joy', 'neutral', 'pride', 'relief', 'sadness', 'shame', 'surprise', 'trust']\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, layer in tqdm(enumerate(extraction_layers), total=len(extraction_layers)):\n",
    "    # For each layer, process all examples\n",
    "    for n, example in results.items():\n",
    "        p = example[\"layers\"][i][f\"layer_{i}\"][\"probs\"][-1]  # [C]\n",
    "        top1_idx = int(p.argmax())\n",
    "        top1_label = emotions_list[top1_idx]\n",
    "        top1_conf = float(p[top1_idx])\n",
    "\n",
    "        # top-k breakdown\n",
    "        k = 5\n",
    "        topk = torch.topk(p, k)\n",
    "        topk_labels = [emotions_list[i] for i in topk.indices.tolist()]\n",
    "        topk_probs = topk.values.tolist()\n",
    "\n",
    "        # Add this result to our list\n",
    "        all_results.append({\n",
    "            \"layer\": i,\n",
    "            \"prompt\": example[\"prompt\"],\n",
    "            \"top1_label\": top1_label,\n",
    "            \"top1_conf\": top1_conf,\n",
    "            \"topk_labels\": str(topk_labels),  # Convert list to string for DataFrame storage\n",
    "            \"topk_probs\": str(topk_probs)     # Convert list to string for DataFrame storage\n",
    "        })\n",
    "\n",
    "# Create DataFrame from all results at once\n",
    "layer_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Save to CSV\n",
    "layer_results.to_csv(f\"C:/Users/kchun/Desktop/emo-llm/probe_results/olmo-1b-hf/all_layers_probe_results_loc_7.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "57032322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer</th>\n",
       "      <th>prompt</th>\n",
       "      <th>top1_label</th>\n",
       "      <th>top1_conf</th>\n",
       "      <th>topk_labels</th>\n",
       "      <th>topk_probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>When you discuss your opinions with your paren...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.216636</td>\n",
       "      <td>['disgust', 'guilt', 'pride', 'boredom', 'sadn...</td>\n",
       "      <td>[0.21663640439510345, 0.20565952360630035, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>If your classmate talks back to you when there...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.252190</td>\n",
       "      <td>['pride', 'guilt', 'disgust', 'boredom', 'sadn...</td>\n",
       "      <td>[0.2521899938583374, 0.20404501259326935, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>If some older people like your parents are dis...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.236469</td>\n",
       "      <td>['pride', 'guilt', 'disgust', 'boredom', 'sadn...</td>\n",
       "      <td>[0.23646938800811768, 0.1907491385936737, 0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>When your classmate says the Earth is flat and...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.229791</td>\n",
       "      <td>['disgust', 'pride', 'guilt', 'boredom', 'sadn...</td>\n",
       "      <td>[0.22979050874710083, 0.18976172804832458, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>When you know you're right, but the others say...</td>\n",
       "      <td>disgust</td>\n",
       "      <td>0.217641</td>\n",
       "      <td>['disgust', 'pride', 'guilt', 'boredom', 'sadn...</td>\n",
       "      <td>[0.21764126420021057, 0.19767293334007263, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>15</td>\n",
       "      <td>You are shopping at a local grocery store. Bec...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312765</td>\n",
       "      <td>['joy', 'guilt', 'pride', 'relief', 'neutral']</td>\n",
       "      <td>[0.3127647638320923, 0.24699753522872925, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>15</td>\n",
       "      <td>You are attending a formal party at your boss'...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.351042</td>\n",
       "      <td>['pride', 'relief', 'neutral', 'joy', 'guilt']</td>\n",
       "      <td>[0.35104164481163025, 0.155538409948349, 0.126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>15</td>\n",
       "      <td>You are leaving class with an acquaintance you...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.532962</td>\n",
       "      <td>['pride', 'joy', 'guilt', 'disgust', 'relief']</td>\n",
       "      <td>[0.5329621434211731, 0.11186456680297852, 0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846</th>\n",
       "      <td>15</td>\n",
       "      <td>You are assigned to give a presentation for cl...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.331702</td>\n",
       "      <td>['pride', 'joy', 'guilt', 'relief', 'neutral']</td>\n",
       "      <td>[0.3317016363143921, 0.223406121134758, 0.2171...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6847</th>\n",
       "      <td>15</td>\n",
       "      <td>You are at a public beach and you feel like go...</td>\n",
       "      <td>pride</td>\n",
       "      <td>0.474606</td>\n",
       "      <td>['pride', 'disgust', 'guilt', 'joy', 'neutral']</td>\n",
       "      <td>[0.4746059477329254, 0.15246497094631195, 0.10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6848 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      layer                                             prompt top1_label  \\\n",
       "0         0  When you discuss your opinions with your paren...    disgust   \n",
       "1         0  If your classmate talks back to you when there...      pride   \n",
       "2         0  If some older people like your parents are dis...      pride   \n",
       "3         0  When your classmate says the Earth is flat and...    disgust   \n",
       "4         0  When you know you're right, but the others say...    disgust   \n",
       "...     ...                                                ...        ...   \n",
       "6843     15  You are shopping at a local grocery store. Bec...        joy   \n",
       "6844     15  You are attending a formal party at your boss'...      pride   \n",
       "6845     15  You are leaving class with an acquaintance you...      pride   \n",
       "6846     15  You are assigned to give a presentation for cl...      pride   \n",
       "6847     15  You are at a public beach and you feel like go...      pride   \n",
       "\n",
       "      top1_conf                                        topk_labels  \\\n",
       "0      0.216636  ['disgust', 'guilt', 'pride', 'boredom', 'sadn...   \n",
       "1      0.252190  ['pride', 'guilt', 'disgust', 'boredom', 'sadn...   \n",
       "2      0.236469  ['pride', 'guilt', 'disgust', 'boredom', 'sadn...   \n",
       "3      0.229791  ['disgust', 'pride', 'guilt', 'boredom', 'sadn...   \n",
       "4      0.217641  ['disgust', 'pride', 'guilt', 'boredom', 'sadn...   \n",
       "...         ...                                                ...   \n",
       "6843   0.312765     ['joy', 'guilt', 'pride', 'relief', 'neutral']   \n",
       "6844   0.351042     ['pride', 'relief', 'neutral', 'joy', 'guilt']   \n",
       "6845   0.532962     ['pride', 'joy', 'guilt', 'disgust', 'relief']   \n",
       "6846   0.331702     ['pride', 'joy', 'guilt', 'relief', 'neutral']   \n",
       "6847   0.474606    ['pride', 'disgust', 'guilt', 'joy', 'neutral']   \n",
       "\n",
       "                                             topk_probs  \n",
       "0     [0.21663640439510345, 0.20565952360630035, 0.1...  \n",
       "1     [0.2521899938583374, 0.20404501259326935, 0.19...  \n",
       "2     [0.23646938800811768, 0.1907491385936737, 0.18...  \n",
       "3     [0.22979050874710083, 0.18976172804832458, 0.1...  \n",
       "4     [0.21764126420021057, 0.19767293334007263, 0.1...  \n",
       "...                                                 ...  \n",
       "6843  [0.3127647638320923, 0.24699753522872925, 0.19...  \n",
       "6844  [0.35104164481163025, 0.155538409948349, 0.126...  \n",
       "6845  [0.5329621434211731, 0.11186456680297852, 0.10...  \n",
       "6846  [0.3317016363143921, 0.223406121134758, 0.2171...  \n",
       "6847  [0.4746059477329254, 0.15246497094631195, 0.10...  \n",
       "\n",
       "[6848 rows x 6 columns]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_results = pd.read_csv(r\"C:/Users/kchun/Desktop/emo-llm/probe_results/olmo-1b-hf/all_layers_probe_results_loc_7.csv\")\n",
    "layer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "17354c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.2777541279792785\n",
      "['disgust', 'boredom', 'pride', 'guilt', 'sadness']\n",
      "[0.27775412797927856, 0.19443608820438385, 0.1654031127691269, 0.13947369158267975, 0.0988512858748436]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "anger\n",
      "0.4967378675937652\n",
      "['anger', 'disgust', 'boredom', 'sadness', 'guilt']\n",
      "[0.49673786759376526, 0.2688058614730835, 0.1254473775625229, 0.06104591116309166, 0.029865814372897148]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.3435211479663849\n",
      "['disgust', 'guilt', 'pride', 'anger', 'boredom']\n",
      "[0.3435211479663849, 0.1629500389099121, 0.15958641469478607, 0.099403977394104, 0.08278924226760864]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "guilt\n",
      "0.3525266647338867\n",
      "['guilt', 'disgust', 'anger', 'pride', 'boredom']\n",
      "[0.3525266647338867, 0.21139666438102722, 0.15349355340003967, 0.08194513618946075, 0.05070943012833595]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "guilt\n",
      "0.5137351751327515\n",
      "['guilt', 'pride', 'sadness', 'disgust', 'anger']\n",
      "[0.5137351751327515, 0.1064639464020729, 0.09590649604797363, 0.07892061769962311, 0.05591454729437828]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "guilt\n",
      "0.7046146392822266\n",
      "['guilt', 'disgust', 'anger', 'sadness', 'boredom']\n",
      "[0.7046146392822266, 0.10621678084135056, 0.0768226683139801, 0.049963392317295074, 0.01816423237323761]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "guilt\n",
      "0.4211510419845581\n",
      "['guilt', 'disgust', 'boredom', 'pride', 'sadness']\n",
      "[0.4211510419845581, 0.3357030749320984, 0.08804307132959366, 0.07216623425483704, 0.026315130293369293]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.7181845903396606\n",
      "['disgust', 'guilt', 'boredom', 'pride', 'sadness']\n",
      "[0.7181845903396606, 0.07925794273614883, 0.06384124606847763, 0.052367668598890305, 0.0508575439453125]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.9633514285087584\n",
      "['disgust', 'pride', 'anger', 'boredom', 'fear']\n",
      "[0.9633514285087585, 0.0184364952147007, 0.005927851889282465, 0.005125919822603464, 0.0035107042640447617]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.7408742904663086\n",
      "['disgust', 'anger', 'boredom', 'pride', 'guilt']\n",
      "[0.7408742904663086, 0.055907778441905975, 0.05169864743947983, 0.04859274625778198, 0.048013415187597275]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.5531681776046753\n",
      "['disgust', 'pride', 'anger', 'sadness', 'guilt']\n",
      "[0.5531681776046753, 0.12229660153388977, 0.10667002201080322, 0.06516982614994049, 0.057827118784189224]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "pride\n",
      "0.2508799433708191\n",
      "['pride', 'anger', 'boredom', 'disgust', 'guilt']\n",
      "[0.2508799433708191, 0.24413369596004486, 0.18252205848693848, 0.09286894649267197, 0.07584085315465927]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "disgust\n",
      "0.5129235982894897\n",
      "['disgust', 'pride', 'boredom', 'guilt', 'anger']\n",
      "[0.5129235982894897, 0.1318071484565735, 0.12118566036224365, 0.04881563410162926, 0.04604232683777809]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "boredom\n",
      "0.2878499925136566\n",
      "['boredom', 'disgust', 'guilt', 'neutral', 'joy']\n",
      "[0.2878499925136566, 0.2811211347579956, 0.1052769348025322, 0.08066099137067795, 0.057689961045980453]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "boredom\n",
      "0.3114771842956543\n",
      "['boredom', 'disgust', 'joy', 'guilt', 'neutral']\n",
      "[0.3114771842956543, 0.2197013795375824, 0.11424700915813446, 0.11363717913627625, 0.09815172106027603]\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "When your parents take their bad morning mood out on you, even though it's none of your business, you think that people who are in a bad temper don't necessarily have to let it come out on other people if it isn't necessary.\n",
      "pride\n",
      "0.5448546409606934\n",
      "['pride', 'joy', 'disgust', 'guilt', 'relief']\n",
      "[0.5448546409606934, 0.10952689498662949, 0.09573128819465637, 0.08119785040616989, 0.07173750549554825]\n"
     ]
    }
   ],
   "source": [
    "for i in extraction_layers:\n",
    "    layer_i = layer_results.loc[layer_results[\"layer\"] == i]\n",
    "    # print(layer_i)\n",
    "    print(layer_i[\"prompt\"].iloc[17])\n",
    "    print(layer_i[\"prompt\"].iloc[17])\n",
    "    print(layer_i[\"top1_label\"].iloc[17])\n",
    "    print(layer_i[\"top1_conf\"].iloc[17])\n",
    "    print(layer_i[\"topk_labels\"].iloc[17])\n",
    "    print(layer_i[\"topk_probs\"].iloc[17])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a515544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([428, 26, 1, 128, 2304])\n",
      "torch.Size([128, 2304])\n",
      "torch.Size([128, 13])\n"
     ]
    }
   ],
   "source": [
    "print(all_hidden_states.shape)                 # expect [428, 26, 1, 128, 2304]\n",
    "print(hs_slice.shape)                          # expect [428, 2304]\n",
    "print(results[layer][loc_id][-1]['probs'].shape)  # expect [428, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42c58502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>scenarios</th>\n",
       "      <th>emotion_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you discuss your opinions with your paren...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If your classmate talks back to you when there...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anger</td>\n",
       "      <td>If some older people like your parents are dis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When your classmate says the Earth is flat and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anger</td>\n",
       "      <td>When you know you're right, but the others say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are shopping at a local grocery store. Bec...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are attending a formal party at your boss'...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are leaving class with an acquaintance you...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are assigned to give a presentation for cl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>Embarrassment</td>\n",
       "      <td>You are at a public beach and you feel like go...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                          scenarios  \\\n",
       "0            Anger  When you discuss your opinions with your paren...   \n",
       "1            Anger  If your classmate talks back to you when there...   \n",
       "2            Anger  If some older people like your parents are dis...   \n",
       "3            Anger  When your classmate says the Earth is flat and...   \n",
       "4            Anger  When you know you're right, but the others say...   \n",
       "..             ...                                                ...   \n",
       "423  Embarrassment  You are shopping at a local grocery store. Bec...   \n",
       "424  Embarrassment  You are attending a formal party at your boss'...   \n",
       "425  Embarrassment  You are leaving class with an acquaintance you...   \n",
       "426  Embarrassment  You are assigned to give a presentation for cl...   \n",
       "427  Embarrassment  You are at a public beach and you feel like go...   \n",
       "\n",
       "     emotion_id  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "..          ...  \n",
       "423           7  \n",
       "424           7  \n",
       "425           7  \n",
       "426           7  \n",
       "427           7  \n",
       "\n",
       "[428 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8405e4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: {'probs': tensor([[5.6326e-01, 1.0225e-02, 1.9526e-01,  ..., 1.3233e-02, 3.7954e-05,\n",
       "           8.2605e-04],\n",
       "          [5.6326e-01, 1.0225e-02, 1.9526e-01,  ..., 1.3233e-02, 3.7954e-05,\n",
       "           8.2605e-04],\n",
       "          [5.6326e-01, 1.0225e-02, 1.9526e-01,  ..., 1.3233e-02, 3.7954e-05,\n",
       "           8.2605e-04],\n",
       "          ...,\n",
       "          [7.5158e-01, 1.4709e-05, 1.3389e-04,  ..., 2.4577e-02, 1.2404e-04,\n",
       "           1.1995e-02],\n",
       "          [6.9839e-01, 1.4840e-04, 3.2622e-03,  ..., 4.1547e-02, 1.2068e-03,\n",
       "           2.0132e-02],\n",
       "          [7.1981e-01, 1.2540e-06, 3.9046e-05,  ..., 8.3047e-03, 1.5154e-04,\n",
       "           5.8605e-03]]),\n",
       "  'preds': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0])}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5fba13ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hidden_states[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7e9834b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [ 2.8177e-02,  1.3913e-02,  1.7546e-01,  ..., -5.7460e-02,\n",
       "            -6.6875e-02,  6.7497e-02],\n",
       "           [ 6.6342e-02,  4.6441e-02,  4.6112e-02,  ..., -2.0023e-02,\n",
       "            -1.0388e-01,  5.7816e-02],\n",
       "           [ 1.1436e-02, -2.0397e-01,  4.0475e-01,  ...,  3.3570e-01,\n",
       "             7.2272e-02, -1.0812e-02]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [-5.1175e-02, -2.8365e-03,  9.7142e-02,  ..., -2.6369e-02,\n",
       "            -1.4363e-01,  6.5863e-03],\n",
       "           [-5.6694e-02, -9.6104e-02, -6.7562e-02,  ..., -2.0089e-02,\n",
       "            -1.1501e-01,  8.2200e-02],\n",
       "           [-3.1351e-03, -1.6963e-02,  7.2229e-02,  ..., -1.0894e-02,\n",
       "            -3.2048e-02,  3.7420e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [ 4.7867e-02, -8.9711e-02,  4.4029e-02,  ...,  3.4213e-02,\n",
       "            -1.1904e-01,  2.0017e-02],\n",
       "           [-5.6718e-02, -5.6030e-02,  4.8696e-02,  ...,  2.2285e-02,\n",
       "            -1.0943e-01,  1.3271e-01],\n",
       "           [ 2.5322e-02, -6.1736e-02,  1.0695e-02,  ...,  4.6091e-02,\n",
       "            -6.0867e-02,  4.0224e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [-4.2912e-02, -4.1035e-02,  1.5670e-02,  ...,  8.9313e-03,\n",
       "            -5.5512e-02, -1.6328e-02],\n",
       "           [-3.4304e-02, -3.5234e-02, -4.1870e-02,  ..., -2.3556e-02,\n",
       "            -9.0010e-02,  2.5613e-02],\n",
       "           [-6.2654e-03, -2.7670e-02, -2.5781e-03,  ..., -3.7387e-02,\n",
       "            -9.7852e-02,  4.5002e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [-1.4455e-02,  2.5412e-02,  9.2640e-03,  ...,  7.8583e-03,\n",
       "             5.7308e-03,  3.8693e-02],\n",
       "           [-8.4565e-02,  6.4192e-02, -1.7812e-02,  ...,  5.9582e-02,\n",
       "             8.4251e-03,  4.8424e-02],\n",
       "           [-1.1028e-02,  4.7057e-02, -6.8026e-02,  ...,  1.7865e-02,\n",
       "             1.5956e-02,  2.9508e-02]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [-1.3269e-02,  4.3054e-03, -1.2653e-02,  ...,  9.0774e-03,\n",
       "            -4.6019e-03, -6.8333e-03],\n",
       "           [-1.2407e-02,  4.6004e-03, -2.7608e-02,  ..., -1.3256e-02,\n",
       "             1.8379e-03, -8.3828e-03],\n",
       "           [-1.9023e-02,  7.8563e-03, -1.6735e-02,  ...,  9.1191e-03,\n",
       "            -6.4491e-04, -2.5150e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [-1.5880e-01,  3.2246e-01,  5.2724e-01,  ..., -3.4165e-02,\n",
       "             1.0193e-02, -3.4357e-01],\n",
       "           [ 1.0259e-01,  3.7069e-02,  1.1214e-01,  ..., -3.2561e-02,\n",
       "             1.1641e-01, -4.7899e-03],\n",
       "           [-1.7429e-03, -1.9088e-01,  3.7707e-01,  ...,  3.2656e-01,\n",
       "             1.6398e-01,  1.2167e-02]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [-1.0985e-01,  1.3954e-01, -9.9131e-03,  ...,  2.2284e-02,\n",
       "            -2.1370e-02, -9.3267e-03],\n",
       "           [ 1.3200e-02, -3.7482e-02,  7.3161e-02,  ..., -4.0021e-02,\n",
       "            -2.2704e-01, -5.0669e-02],\n",
       "           [-2.6199e-02,  1.1323e-02,  8.4845e-02,  ..., -3.8866e-03,\n",
       "            -1.1589e-02,  8.0059e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [ 5.3304e-02, -3.2181e-02, -1.1749e-02,  ...,  6.0363e-02,\n",
       "            -1.3594e-01,  4.9466e-02],\n",
       "           [ 6.2497e-03,  5.2821e-03, -2.5884e-02,  ...,  8.1725e-03,\n",
       "             4.0752e-02, -2.0931e-02],\n",
       "           [ 1.8339e-02, -2.5365e-02, -3.8688e-03,  ...,  2.1482e-02,\n",
       "            -3.8175e-02,  1.0592e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [ 7.7918e-03,  3.3105e-02,  3.0766e-02,  ...,  3.5730e-03,\n",
       "            -2.5252e-02, -8.4604e-03],\n",
       "           [ 1.4800e-02,  2.0485e-03, -3.7779e-03,  ..., -5.1738e-02,\n",
       "            -1.7969e-02,  8.0627e-03],\n",
       "           [ 1.7032e-02,  3.0653e-03,  6.0771e-03,  ..., -2.4387e-02,\n",
       "            -5.5451e-02,  2.1663e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [ 4.0441e-03,  4.2510e-02,  2.5398e-02,  ..., -1.4599e-03,\n",
       "             9.4486e-03,  5.0215e-02],\n",
       "           [-1.2718e-02,  3.1338e-02, -4.9487e-02,  ...,  2.7956e-03,\n",
       "             1.6458e-02, -6.4490e-04],\n",
       "           [-2.1441e-02,  1.9088e-02, -8.1765e-02,  ..., -2.1073e-02,\n",
       "             1.8546e-02,  1.4297e-02]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [-4.7513e-03,  6.4768e-03, -1.0601e-02,  ...,  1.0494e-02,\n",
       "            -7.0031e-03,  1.5043e-02],\n",
       "           [-1.3883e-02,  6.9455e-03, -1.6532e-02,  ..., -8.6727e-03,\n",
       "            -9.2251e-03, -2.7233e-03],\n",
       "           [-3.1547e-03,  1.9920e-02, -3.0534e-02,  ...,  1.2295e-02,\n",
       "            -1.6213e-03, -3.4411e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [-2.1748e-02, -1.5942e-02,  4.6012e-02,  ...,  8.8119e-02,\n",
       "             1.5625e-01, -1.9611e-01],\n",
       "           [ 9.7565e-03, -1.0469e-01, -3.0475e-02,  ...,  1.0612e-01,\n",
       "             1.5508e-01, -5.4963e-02],\n",
       "           [ 2.5095e-02, -2.1912e-01,  4.0991e-01,  ...,  3.8420e-01,\n",
       "             7.6467e-02, -9.6454e-03]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [-7.6959e-02,  7.4518e-02, -3.9628e-04,  ..., -2.0948e-02,\n",
       "             3.3751e-02, -3.5384e-02],\n",
       "           [ 5.4769e-02,  5.7590e-02,  3.8139e-02,  ..., -1.5463e-02,\n",
       "            -7.1461e-02, -9.2405e-03],\n",
       "           [ 4.0378e-03, -2.1062e-02,  4.7358e-02,  ...,  2.1060e-02,\n",
       "             3.2403e-02,  2.7686e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [-5.5405e-02,  8.5672e-02, -7.3845e-02,  ...,  7.1244e-02,\n",
       "             3.2702e-02, -4.9311e-02],\n",
       "           [-2.1651e-02, -1.7591e-01,  6.4556e-02,  ...,  1.0900e-02,\n",
       "             7.3843e-02,  1.0474e-01],\n",
       "           [-1.1625e-02, -6.2809e-02, -2.0429e-02,  ...,  2.9656e-02,\n",
       "            -7.2685e-02, -3.5758e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [ 3.1697e-02,  1.2445e-02, -2.3524e-02,  ..., -3.2183e-02,\n",
       "             8.2676e-03,  9.9267e-03],\n",
       "           [ 1.9191e-02, -2.2613e-02, -4.3335e-02,  ..., -2.3647e-02,\n",
       "            -3.6363e-02, -8.1191e-03],\n",
       "           [ 3.0502e-02, -7.5314e-03, -5.4232e-03,  ..., -3.3876e-02,\n",
       "            -5.0098e-02,  6.5162e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [-3.1873e-02,  4.6032e-02, -2.9028e-02,  ...,  4.0758e-02,\n",
       "             2.0831e-02,  3.9668e-02],\n",
       "           [-1.8670e-02,  5.9154e-02, -3.7684e-02,  ...,  3.0683e-03,\n",
       "             6.6070e-03,  6.2939e-03],\n",
       "           [-1.7414e-02,  5.8298e-02, -7.9943e-02,  ..., -3.0726e-03,\n",
       "            -2.4102e-02, -5.7845e-03]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [-5.1719e-03,  1.3899e-02, -3.0515e-02,  ...,  3.0824e-03,\n",
       "             6.8475e-04,  5.0579e-03],\n",
       "           [-3.9764e-03,  9.2465e-03, -1.7070e-02,  ...,  1.1861e-02,\n",
       "            -9.6034e-03, -1.8158e-03],\n",
       "           [ 6.3474e-03,  3.1179e-03, -4.2309e-02,  ...,  6.3562e-03,\n",
       "             9.5720e-03, -1.1978e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [ 5.4120e-02,  6.2802e-02, -5.0038e-02,  ...,  2.4183e-01,\n",
       "            -5.0703e-02,  1.5098e-02],\n",
       "           [-5.3172e-02,  3.9660e-02, -9.8037e-02,  ..., -1.1208e-01,\n",
       "             2.0189e-01,  1.8290e-02],\n",
       "           [ 1.9630e-02, -1.9165e-01,  3.7317e-01,  ...,  3.4680e-01,\n",
       "             1.1936e-01,  2.1064e-03]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [-2.9389e-02, -2.8783e-02, -1.2757e-01,  ...,  1.2809e-03,\n",
       "             3.6863e-03, -4.1119e-02],\n",
       "           [ 5.3363e-02, -1.7915e-02,  5.7495e-02,  ..., -2.0830e-02,\n",
       "            -1.1030e-01, -1.1845e-02],\n",
       "           [-4.8744e-02, -4.8353e-02,  5.5015e-02,  ..., -1.2992e-02,\n",
       "            -2.9440e-02,  4.0183e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [ 1.8321e-02,  2.2926e-02,  1.8949e-02,  ..., -3.6956e-02,\n",
       "             1.2292e-01,  4.8906e-02],\n",
       "           [-6.2496e-02,  4.0450e-02, -7.0323e-03,  ...,  7.2809e-03,\n",
       "            -3.9530e-02,  1.6404e-02],\n",
       "           [-4.4805e-02, -3.2749e-02, -4.2044e-02,  ..., -1.1523e-03,\n",
       "            -5.7408e-02,  1.1367e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [ 2.5123e-02,  1.0104e-02, -5.9356e-02,  ...,  2.1201e-02,\n",
       "            -4.1123e-02, -2.4295e-02],\n",
       "           [-1.1810e-03, -3.9392e-02, -3.6400e-02,  ..., -2.7389e-02,\n",
       "            -2.1240e-02, -3.2494e-02],\n",
       "           [ 5.6155e-02, -1.7249e-02, -2.0799e-02,  ..., -4.5372e-02,\n",
       "            -5.2633e-02,  9.7686e-03]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [ 6.6340e-02, -4.0367e-02,  7.9592e-03,  ...,  2.7932e-02,\n",
       "             1.2755e-02, -2.8944e-02],\n",
       "           [ 6.9466e-03,  3.6074e-03, -5.0565e-02,  ...,  1.9343e-02,\n",
       "             1.7941e-03, -2.6628e-02],\n",
       "           [-4.0431e-02,  4.5689e-02, -5.6158e-02,  ...,  1.5425e-02,\n",
       "            -2.9958e-02, -2.6622e-02]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [ 1.3748e-02, -3.0545e-02,  2.1777e-03,  ...,  7.4671e-03,\n",
       "             2.1398e-02, -1.1722e-02],\n",
       "           [-4.4642e-03, -1.4369e-02, -1.2495e-02,  ...,  1.6054e-02,\n",
       "            -5.0639e-03, -2.4278e-02],\n",
       "           [-2.4361e-03,  1.6150e-02, -2.7339e-02,  ...,  2.7571e-02,\n",
       "            -1.5521e-02, -5.3316e-03]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [ 1.3011e-01,  1.2173e-01,  2.2868e-01,  ..., -2.6515e-02,\n",
       "             1.7533e-01,  5.6508e-02],\n",
       "           [ 3.4246e-01,  1.3049e-01, -2.7311e-02,  ...,  7.0986e-02,\n",
       "            -1.1542e-01,  7.4481e-02],\n",
       "           [ 2.6811e-02, -1.8953e-01,  3.3876e-01,  ...,  3.9567e-01,\n",
       "             5.2776e-02,  2.4575e-03]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [ 1.4567e-02,  3.2259e-02, -3.0147e-02,  ..., -7.1599e-02,\n",
       "             3.7249e-03,  5.3648e-02],\n",
       "           [ 3.2821e-02, -1.9647e-01, -2.0557e-01,  ...,  1.8018e-02,\n",
       "            -1.9110e-01, -4.1525e-02],\n",
       "           [ 1.0130e-02, -6.5645e-02,  1.9948e-02,  ..., -2.8708e-02,\n",
       "            -3.6141e-02,  6.8454e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [-8.2191e-03, -4.1144e-02, -2.0624e-03,  ...,  1.2701e-02,\n",
       "            -1.2065e-01,  1.7594e-03],\n",
       "           [-2.1760e-02, -1.5080e-01,  6.8884e-02,  ..., -1.2737e-02,\n",
       "             4.5244e-02, -1.4452e-02],\n",
       "           [-5.1156e-02, -3.4875e-02, -5.4420e-03,  ..., -1.2993e-02,\n",
       "            -4.8500e-02,  1.0282e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [-4.7478e-03, -1.2569e-02,  1.8661e-02,  ..., -3.3930e-02,\n",
       "            -5.5859e-02,  2.9796e-02],\n",
       "           [ 1.7053e-02,  7.3674e-03, -1.1241e-02,  ..., -5.2013e-02,\n",
       "            -4.3060e-02, -2.9043e-02],\n",
       "           [ 2.2962e-02, -6.5989e-03,  3.4932e-02,  ...,  1.0095e-02,\n",
       "            -6.8466e-02,  1.0243e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [-4.0188e-03,  6.7925e-03,  8.2391e-03,  ...,  1.4060e-02,\n",
       "             3.2617e-02,  5.3376e-03],\n",
       "           [-2.7643e-02, -3.5668e-03, -1.7792e-02,  ...,  5.7203e-02,\n",
       "            -2.7143e-02,  2.5883e-02],\n",
       "           [-1.9485e-02,  2.4905e-02, -4.0030e-02,  ..., -1.1083e-03,\n",
       "            -9.8551e-03,  2.0028e-02]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [ 6.1354e-03, -2.8226e-02,  1.2591e-02,  ...,  4.4903e-03,\n",
       "            -4.7017e-03, -9.0720e-03],\n",
       "           [ 3.1409e-03, -2.2981e-04, -2.4479e-02,  ...,  1.7019e-02,\n",
       "            -2.6595e-03, -9.1266e-03],\n",
       "           [ 9.3057e-03,  7.3526e-03, -2.1903e-02,  ...,  3.1765e-02,\n",
       "            -3.1367e-02, -1.4329e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           [ 1.6162e-01,  8.1971e-02, -1.6302e-01,  ...,  2.5530e-01,\n",
       "            -3.0043e-01,  1.0108e-01],\n",
       "           ...,\n",
       "           [-2.2882e-01, -2.3105e-01,  2.2370e-01,  ..., -9.3077e-03,\n",
       "             9.8920e-02, -1.6302e-02],\n",
       "           [-8.8638e-02, -6.4366e-02, -1.3018e-01,  ...,  2.1282e-01,\n",
       "             2.0980e-02, -1.5224e-01],\n",
       "           [ 3.4625e-02, -1.7861e-01,  3.9290e-01,  ...,  4.0451e-01,\n",
       "             1.5987e-01, -7.2754e-02]]],\n",
       "\n",
       "\n",
       "         [[[-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           [-2.9435e-03,  6.6144e-02, -1.3014e-01,  ...,  4.6945e-03,\n",
       "            -2.1899e-01,  1.1766e-01],\n",
       "           ...,\n",
       "           [-8.1547e-02, -5.5181e-02, -2.8353e-02,  ..., -2.0798e-01,\n",
       "            -1.6939e-02,  1.0001e-01],\n",
       "           [ 2.4132e-02, -6.9073e-02,  6.0858e-02,  ..., -1.0265e-01,\n",
       "            -1.1843e-01, -1.4361e-02],\n",
       "           [-3.1651e-02, -6.4048e-02,  5.4261e-02,  ..., -2.5702e-02,\n",
       "            -4.9372e-02,  2.7181e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           [ 1.7049e-02,  1.8071e-02, -3.5125e-02,  ...,  2.2997e-03,\n",
       "            -1.1874e-01,  7.8436e-02],\n",
       "           ...,\n",
       "           [ 4.5247e-02,  4.5805e-02, -4.0747e-02,  ...,  6.8568e-02,\n",
       "             6.8686e-02,  1.5733e-02],\n",
       "           [-3.5780e-03,  4.5171e-02, -4.2979e-02,  ..., -2.3754e-02,\n",
       "            -9.9115e-02,  9.8889e-02],\n",
       "           [-5.2337e-02, -1.9922e-02, -4.5098e-02,  ...,  3.8868e-02,\n",
       "            -1.8887e-02, -4.2600e-02]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           [ 2.8696e-02, -1.8701e-02,  8.3907e-03,  ..., -7.5958e-03,\n",
       "            -3.7726e-02,  4.6621e-02],\n",
       "           ...,\n",
       "           [ 3.4990e-02,  2.0133e-02, -1.6914e-02,  ..., -2.0756e-02,\n",
       "            -2.4229e-02,  3.4685e-02],\n",
       "           [ 1.0849e-01,  1.4349e-02, -3.3800e-02,  ...,  5.2102e-03,\n",
       "            -5.0991e-02,  3.5657e-02],\n",
       "           [ 4.5428e-02, -1.8713e-02, -2.2257e-02,  ..., -7.9172e-03,\n",
       "            -5.2414e-02,  3.5846e-02]]],\n",
       "\n",
       "\n",
       "         [[[-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           [-1.3475e-03, -1.8241e-03, -2.3162e-02,  ...,  9.8429e-03,\n",
       "            -4.9175e-02, -1.1790e-02],\n",
       "           ...,\n",
       "           [-2.6516e-02,  3.4484e-02, -3.6273e-02,  ...,  1.0514e-02,\n",
       "             3.1343e-02,  2.0950e-03],\n",
       "           [-7.7736e-02,  3.9651e-02, -1.8733e-02,  ...,  2.5862e-02,\n",
       "            -1.9354e-02, -2.8811e-02],\n",
       "           [-3.3655e-02,  4.9849e-02, -5.9157e-02,  ...,  3.2038e-03,\n",
       "            -4.2666e-02, -2.2539e-02]]],\n",
       "\n",
       "\n",
       "         [[[-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           [-5.6128e-02, -9.7068e-03, -6.4163e-02,  ..., -3.4930e-03,\n",
       "             3.0731e-03, -3.4752e-02],\n",
       "           ...,\n",
       "           [-7.1258e-03, -1.8017e-02,  2.8811e-04,  ...,  9.7631e-04,\n",
       "             2.5204e-03, -1.6995e-02],\n",
       "           [-2.5486e-02, -6.6652e-03, -3.5095e-02,  ...,  7.7861e-03,\n",
       "            -2.2424e-02, -6.3568e-03],\n",
       "           [-3.3111e-03,  9.7593e-03, -1.9263e-02,  ...,  5.8380e-03,\n",
       "            -2.1763e-02, -5.2112e-03]]]]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f6354a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [ 0.0282,  0.0139,  0.1755,  ..., -0.0575, -0.0669,  0.0675],\n",
       "          [ 0.0663,  0.0464,  0.0461,  ..., -0.0200, -0.1039,  0.0578],\n",
       "          [ 0.0114, -0.2040,  0.4048,  ...,  0.3357,  0.0723, -0.0108]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [-0.1588,  0.3225,  0.5272,  ..., -0.0342,  0.0102, -0.3436],\n",
       "          [ 0.1026,  0.0371,  0.1121,  ..., -0.0326,  0.1164, -0.0048],\n",
       "          [-0.0017, -0.1909,  0.3771,  ...,  0.3266,  0.1640,  0.0122]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [-0.0217, -0.0159,  0.0460,  ...,  0.0881,  0.1563, -0.1961],\n",
       "          [ 0.0098, -0.1047, -0.0305,  ...,  0.1061,  0.1551, -0.0550],\n",
       "          [ 0.0251, -0.2191,  0.4099,  ...,  0.3842,  0.0765, -0.0096]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [ 0.0541,  0.0628, -0.0500,  ...,  0.2418, -0.0507,  0.0151],\n",
       "          [-0.0532,  0.0397, -0.0980,  ..., -0.1121,  0.2019,  0.0183],\n",
       "          [ 0.0196, -0.1917,  0.3732,  ...,  0.3468,  0.1194,  0.0021]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [ 0.1301,  0.1217,  0.2287,  ..., -0.0265,  0.1753,  0.0565],\n",
       "          [ 0.3425,  0.1305, -0.0273,  ...,  0.0710, -0.1154,  0.0745],\n",
       "          [ 0.0268, -0.1895,  0.3388,  ...,  0.3957,  0.0528,  0.0025]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          [ 0.1616,  0.0820, -0.1630,  ...,  0.2553, -0.3004,  0.1011],\n",
       "          ...,\n",
       "          [-0.2288, -0.2311,  0.2237,  ..., -0.0093,  0.0989, -0.0163],\n",
       "          [-0.0886, -0.0644, -0.1302,  ...,  0.2128,  0.0210, -0.1522],\n",
       "          [ 0.0346, -0.1786,  0.3929,  ...,  0.4045,  0.1599, -0.0728]]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70b0a729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'here']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string =  \"splithere\"\n",
    "string.split(\"split\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73db0277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round_number</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>prolific_id</th>\n",
       "      <th>anger</th>\n",
       "      <th>boredom</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>guilt</th>\n",
       "      <th>...</th>\n",
       "      <th>dependable</th>\n",
       "      <th>anxious</th>\n",
       "      <th>open</th>\n",
       "      <th>quiet</th>\n",
       "      <th>sympathetic</th>\n",
       "      <th>disorganized</th>\n",
       "      <th>calm</th>\n",
       "      <th>conventional</th>\n",
       "      <th>did_you_lie?</th>\n",
       "      <th>original_demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>215</td>\n",
       "      <td>2021/07/20 4:12:25 pm EET</td>\n",
       "      <td>f29aa2d9930b2c3005e4176f70479f9e</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>216</td>\n",
       "      <td>2021/07/20 4:24:44 pm EET</td>\n",
       "      <td>18fa800cc02bc318c94d6415c23172cd</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>217</td>\n",
       "      <td>2021/07/20 4:25:59 pm EET</td>\n",
       "      <td>99907d478cdbaeb5388db3459408282c</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>218</td>\n",
       "      <td>2021/07/20 4:27:24 pm EET</td>\n",
       "      <td>2475d464084cccf82ac3e72ea8721a5c</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>round-2</td>\n",
       "      <td>anger</td>\n",
       "      <td>219</td>\n",
       "      <td>2021/07/20 4:29:02 pm EET</td>\n",
       "      <td>cb83b6f7181863ab7ccd76e203fb2a9e</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>--</td>\n",
       "      <td>ORIGINAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  round_number emotion  text_id                  timestamp  \\\n",
       "0      round-2   anger      215  2021/07/20 4:12:25 pm EET   \n",
       "1      round-2   anger      216  2021/07/20 4:24:44 pm EET   \n",
       "2      round-2   anger      217  2021/07/20 4:25:59 pm EET   \n",
       "3      round-2   anger      218  2021/07/20 4:27:24 pm EET   \n",
       "4      round-2   anger      219  2021/07/20 4:29:02 pm EET   \n",
       "\n",
       "                        prolific_id  anger  boredom  disgust  fear  guilt  \\\n",
       "0  f29aa2d9930b2c3005e4176f70479f9e      1        3        1     1      1   \n",
       "1  18fa800cc02bc318c94d6415c23172cd      4        1        1     2      1   \n",
       "2  99907d478cdbaeb5388db3459408282c      1        3        2     2      2   \n",
       "3  2475d464084cccf82ac3e72ea8721a5c      1        5        2     1      1   \n",
       "4  cb83b6f7181863ab7ccd76e203fb2a9e      1        3        1     1      1   \n",
       "\n",
       "   ...  dependable  anxious  open  quiet  sympathetic  disorganized  calm  \\\n",
       "0  ...         7.0      5.0   7.0    7.0          7.0           2.0   3.0   \n",
       "1  ...         6.0      5.0   5.0    4.0          5.0           3.0   4.0   \n",
       "2  ...         5.0      6.0   3.0    7.0          7.0           4.0   6.0   \n",
       "3  ...         5.0      5.0   5.0    5.0          5.0           4.0   5.0   \n",
       "4  ...         5.0      5.0   6.0    3.0          6.0           5.0   5.0   \n",
       "\n",
       "  conventional did_you_lie? original_demographics  \n",
       "0          2.0           --              ORIGINAL  \n",
       "1          4.0           --              ORIGINAL  \n",
       "2          5.0           --              ORIGINAL  \n",
       "3          3.0           --              ORIGINAL  \n",
       "4          3.0           --              ORIGINAL  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/enVent_gen_Data.csv\", encoding='ISO-8859-1')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d20c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people get under my skin. Like for example if an entitled customer shows up at my work and  demands to speak to my manager for a simple issue that I can resolve. This happens on almost a daily occurrence and it really makes me ....\n"
     ]
    }
   ],
   "source": [
    "print(df[\"hidden_emo_text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0aebb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2db3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060360fbf5714f22bedbabd1133df1f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ccbeeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python main.py --model_index=0 --emotion_probing_binary --extract_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d69dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
